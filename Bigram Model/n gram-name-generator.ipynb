{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13974830,"sourceType":"datasetVersion","datasetId":8909519}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# imports & utilities\nimport os\nimport sys\nfrom collections import defaultdict, Counter\nimport math\nimport random\nimport numpy as np\nfrom typing import List, Tuple, Dict, Iterable\n\n# Simple text normalization\ndef normalize_name(s: str) -> str:\n    return s.strip().lower()\n\n# Safe display of generated names (capitalizes first letter)\ndef beautify_name(s: str) -> str:\n    if not s:\n        return s\n    return s.capitalize()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:21:44.890290Z","iopub.execute_input":"2025-12-03T16:21:44.890643Z","iopub.status.idle":"2025-12-03T16:21:44.903075Z","shell.execute_reply.started":"2025-12-03T16:21:44.890617Z","shell.execute_reply":"2025-12-03T16:21:44.901639Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# config\nVOCAB_EXTRA = '.'   # start/end token\nMAX_NAME_LEN = 20   # safety cap for generated names\nDEFAULT_N = 2       # default Markov order (bigram)\nLAPLACE_ALPHA = 1.0 # smoothing\nSEED = 2147483647   # default RNG seed for reproducible sampling\nMAX_GENERATION_ATTEMPTS = 10000  # to avoid infinite loops\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:21:44.905545Z","iopub.execute_input":"2025-12-03T16:21:44.905968Z","iopub.status.idle":"2025-12-03T16:21:44.939722Z","shell.execute_reply.started":"2025-12-03T16:21:44.905933Z","shell.execute_reply":"2025-12-03T16:21:44.938517Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# load dataset\nDATA_PATH = '/kaggle/input/names-dataset-for-bigram-model/names.txt'\n\nif not os.path.exists(DATA_PATH):\n    raise FileNotFoundError(f\"Dataset file not found at '{DATA_PATH}'. Upload names.txt to the working directory.\")\n\nwith open(DATA_PATH, 'r', encoding='utf-8') as f:\n    raw_words = [line.strip() for line in f.readlines() if line.strip()]\n\n# normalize\nwords = [normalize_name(w) for w in raw_words]\n\nprint(f\"Loaded {len(words)} names. Example: {words[:10]}\")\n# peek distinct lengths\nlengths = [len(w) for w in words]\nprint(f\"Shortest: {min(lengths)} chars, Longest: {max(lengths)} chars\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:21:44.941082Z","iopub.execute_input":"2025-12-03T16:21:44.941596Z","iopub.status.idle":"2025-12-03T16:21:44.997933Z","shell.execute_reply.started":"2025-12-03T16:21:44.941528Z","shell.execute_reply":"2025-12-03T16:21:44.996966Z"}},"outputs":[{"name":"stdout","text":"Loaded 32033 names. Example: ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\nShortest: 2 chars, Longest: 15 chars\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# vocabulary\nchars = sorted(list(set(''.join(words))))\nallowed = [c for c in chars if c.isalpha()]\nif len(allowed) < len(chars):\n    print(\"Note: dataset contained non-alpha characters; they will be ignored in vocabulary:\", \n          sorted(set(chars) - set(allowed)))\n\nvocab = [VOCAB_EXTRA] + allowed  # '.' at index 0\nstoi = {s:i for i,s in enumerate(vocab)}\nitos = {i:s for s,i in stoi.items()}\nV = len(vocab)\nprint(f\"Vocabulary ({V} tokens): {vocab}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:21:44.999046Z","iopub.execute_input":"2025-12-03T16:21:44.999374Z","iopub.status.idle":"2025-12-03T16:21:45.014408Z","shell.execute_reply.started":"2025-12-03T16:21:44.999344Z","shell.execute_reply":"2025-12-03T16:21:45.013359Z"}},"outputs":[{"name":"stdout","text":"Vocabulary (27 tokens): ['.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# build n-gram counts up to order N (inclusive)\ndef build_ngram_counts(corpus: Iterable[str], max_order: int = 2) -> Dict[int, Dict[Tuple[str,...], Counter]]:\n    counts = {n: defaultdict(Counter) for n in range(1, max_order+1)}\n    for w in corpus:\n        # wrap with start and end token\n        seq = [VOCAB_EXTRA] + list(w) + [VOCAB_EXTRA]\n        for n in range(1, max_order+1):\n            # context length = n-1\n            for i in range(len(seq) - (n-1)):\n                context = tuple(seq[i:i + (n-1)]) if (n-1) > 0 else tuple()\n                next_token = seq[i + (n-1)]\n                counts[n][context][next_token] += 1\n    return counts\n\n# build counts up to trigram for better robustness\nMAX_ORDER = 3\ncounts = build_ngram_counts(words, max_order=MAX_ORDER)\nfor n in range(1, MAX_ORDER+1):\n    print(f\"Order {n}: contexts = {len(counts[n])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:21:45.016433Z","iopub.execute_input":"2025-12-03T16:21:45.017038Z","iopub.status.idle":"2025-12-03T16:21:45.441587Z","shell.execute_reply.started":"2025-12-03T16:21:45.017006Z","shell.execute_reply":"2025-12-03T16:21:45.440426Z"}},"outputs":[{"name":"stdout","text":"Order 1: contexts = 1\nOrder 2: contexts = 27\nOrder 3: contexts = 601\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# convert counters into probability tables with Laplace smoothing and prepare backoff lookup\n\ndef build_probability_tables(counts: Dict[int, Dict[Tuple[str,...], Counter]],\n                             vocab: List[str],\n                             alpha: float = 1.0) -> Dict[int, Dict[Tuple[str,...], Tuple[List[str], np.ndarray]]]:\n    V = len(vocab)\n    prob_tables = {n: {} for n in counts}\n    for n, ctx_map in counts.items():\n        for ctx, counter in ctx_map.items():\n            # build array over the entire vocab to allow sampling of any token (smoothed)\n            counts_arr = np.array([counter.get(tok, 0) for tok in vocab], dtype=float)\n            counts_arr += alpha  # Laplace\n            probs = counts_arr / counts_arr.sum()\n            prob_tables[n][ctx] = (vocab, probs)\n    return prob_tables\n\nprob_tables = build_probability_tables(counts, vocab, alpha=LAPLACE_ALPHA)\n# quick sanity check: pick a random context\nsome_n = 2\nsome_ctx = next(iter(prob_tables[some_n].keys()))\ntokens_list, probs_arr = prob_tables[some_n][some_ctx]\nprint(f\"Example context (order {some_n}): {some_ctx} -> first tokens: {tokens_list[:8]} | probs sum {probs_arr.sum():.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:21:45.443205Z","iopub.execute_input":"2025-12-03T16:21:45.443500Z","iopub.status.idle":"2025-12-03T16:21:45.462572Z","shell.execute_reply.started":"2025-12-03T16:21:45.443471Z","shell.execute_reply":"2025-12-03T16:21:45.461601Z"}},"outputs":[{"name":"stdout","text":"Example context (order 2): ('.',) -> first tokens: ['.', 'a', 'b', 'c', 'd', 'e', 'f', 'g'] | probs sum 1.000000\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# function to fetch distribution given current context with backoff\n\ndef get_distribution_with_backoff(context: Tuple[str,...],\n                                  prob_tables: Dict[int, Dict[Tuple[str,...], Tuple[List[str], np.ndarray]]],\n                                  max_order: int) -> Tuple[List[str], np.ndarray, int]:\n    # context is a tuple of last tokens (length can be up to max_order-1); contxt length -> decreasing\n    for order in range(min(max_order, len(context)+1), 0, -1):\n        ctx_len_needed = order - 1\n        ctx = tuple(context[-ctx_len_needed:]) if ctx_len_needed > 0 else tuple()\n        if ctx in prob_tables[order]:\n            return prob_tables[order][ctx][0], prob_tables[order][ctx][1], order\n    # fallback: unigram with empty context must exist\n    return prob_tables[1][tuple()][0], prob_tables[1][tuple()][1], 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:21:45.463282Z","iopub.execute_input":"2025-12-03T16:21:45.463516Z","iopub.status.idle":"2025-12-03T16:21:45.494198Z","shell.execute_reply.started":"2025-12-03T16:21:45.463497Z","shell.execute_reply":"2025-12-03T16:21:45.493087Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# sampling function (single name)\ndef sample_name(start_prefix: str,\n                prob_tables: Dict[int, Dict[Tuple[str,...], Tuple[List[str], np.ndarray]]],\n                vocab: List[str],\n                stoi: Dict[str,int],\n                itos: Dict[int,str],\n                max_order: int = 3,\n                rng: np.random.Generator = None,\n                max_len: int = 20) -> str:\n    \n    if rng is None:\n        rng = np.random.default_rng()\n    # normalize prefix\n    prefix = ''.join([c for c in start_prefix.lower() if c.isalpha()])\n    # verify prefix characters are in vocab\n    for ch in prefix:\n        if ch not in vocab:\n            raise ValueError(f\"Character '{ch}' not in vocabulary.\")\n    # initial sequence: '.' + prefix chars\n    seq = [VOCAB_EXTRA] + list(prefix)\n    # If prefix already ends with end token (unlikely), keep it\n    # Now autoregressively sample\n    for step in range(max_len):\n        # context = last (max_order-1) tokens\n        context = tuple(seq[-(max_order-1):]) if (max_order-1) > 0 else tuple()\n        tokens_list, probs_arr, used_order = get_distribution_with_backoff(context, prob_tables, max_order)\n        # sample one token index from tokens_list according to probs_arr\n        next_token = rng.choice(tokens_list, p=probs_arr)\n        if next_token == VOCAB_EXTRA:\n            # end of name\n            break\n        seq.append(next_token)\n        # safety: if name grows beyond cap, stop\n        if len(seq) > max_len:\n            break\n    # build name removing leading dot and any trailing dot\n    # seq = ['.', 'a', 'b', 'c'] -> name 'abc'\n    name = ''.join([t for t in seq if t != VOCAB_EXTRA])\n    return name\n\n# quick test sampling (deterministic rng)\ntest_rng = np.random.default_rng(SEED)\nprint(\"Example sample (no prefix):\", sample_name(\"\", prob_tables, vocab, stoi, itos, max_order=MAX_ORDER, rng=test_rng, max_len=MAX_NAME_LEN))\nprint(\"Example sample (prefix 'am'):\", sample_name(\"am\", prob_tables, vocab, stoi, itos, max_order=MAX_ORDER, rng=test_rng, max_len=MAX_NAME_LEN))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:21:45.496023Z","iopub.execute_input":"2025-12-03T16:21:45.496360Z","iopub.status.idle":"2025-12-03T16:21:45.525775Z","shell.execute_reply.started":"2025-12-03T16:21:45.496327Z","shell.execute_reply":"2025-12-03T16:21:45.524521Z"}},"outputs":[{"name":"stdout","text":"Example sample (no prefix): drena\nExample sample (prefix 'am'): amaystiic\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# prompt and generation\n\ndef prompt_and_generate():\n    print(\"Welcome to Skred's Markov (n-gram) Name Generator\")\n    start = input(\"Enter starting letters for the name (leave empty for any): \").strip().lower()\n    try:\n        k = int(input(\"How many names do you want to generate? (e.g. 10): \").strip())\n        if k <= 0:\n            raise ValueError()\n    except Exception:\n        print(\"Invalid number; defaulting to 10.\")\n        k = 10\n\n    try:\n        order = int(input(f\"Choose Markov order (1..{MAX_ORDER} (N-grams; higher order models create more realistic names)) [default {DEFAULT_N}]: \").strip() or DEFAULT_N)\n        if order < 1 or order > MAX_ORDER:\n            print(f\"Order must be between 1 and {MAX_ORDER}; using default {DEFAULT_N}\")\n            order = DEFAULT_N\n    except Exception:\n        order = DEFAULT_N\n\n    # ask for seed for reproducibility\n    seed_input = input(f\"Enter integer RNG seed (or leave empty for random): \").strip()\n    rng = np.random.default_rng(int(seed_input)) if seed_input else np.random.default_rng()\n\n    # produce unique names\n    generated = []\n    attempts = 0\n    while len(generated) < k and attempts < MAX_GENERATION_ATTEMPTS:\n        name = sample_name(start, prob_tables, vocab, stoi, itos, max_order=order, rng=rng, max_len=MAX_NAME_LEN)\n        pretty = beautify_name(name)\n        if pretty and pretty not in generated:\n            generated.append(pretty)\n        attempts += 1\n\n    print(f\"\\nGenerated {len(generated)} unique names (attempts {attempts}):\")\n    for i, nm in enumerate(generated, 1):\n        print(f\"{i:3d}. {nm}\")\n    if len(generated) < k:\n        print(f\"Could only generate {len(generated)} unique names after {attempts} attempts; try larger tolerance or different prefix.\")\n\n# run prompt\nprompt_and_generate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:21:45.526862Z","iopub.execute_input":"2025-12-03T16:21:45.527391Z","iopub.status.idle":"2025-12-03T16:22:19.166731Z","shell.execute_reply.started":"2025-12-03T16:21:45.527356Z","shell.execute_reply":"2025-12-03T16:22:19.165252Z"}},"outputs":[{"name":"stdout","text":"Welcome to Skred's Markov (n-gram) Name Generator\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter starting letters for the name (leave empty for any):  a\nHow many names do you want to generate? (e.g. 10):  30\nChoose Markov order (1..3 (N-grams; higher order models create more realistic names)) [default 2]:  2\nEnter integer RNG seed (or leave empty for random):  \n"},{"name":"stdout","text":"\nGenerated 30 unique names (attempts 42):\n  1. A\n  2. Ami\n  3. Ayxsaynnanl\n  4. Ameramma\n  5. Anova\n  6. Aricha\n  7. Amima\n  8. Amamabaieryau\n  9. An\n 10. Amahotythauwion\n 11. Aele\n 12. Aen\n 13. Adamilagurabrllete\n 14. Ainehaciloslavydra\n 15. Ari\n 16. Atore\n 17. Ayalyanariee\n 18. Ahasoreemetlsah\n 19. As\n 20. Ak\n 21. Az\n 22. Afw\n 23. Ay\n 24. Andatthaligee\n 25. Ano\n 26. Ah\n 27. Ale\n 28. Ai\n 29. Aleriatr\n 30. Aia\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# compute negative log-likelihood on the training set using our prob_tables (with backoff)\ndef compute_nll_dataset(corpus: Iterable[str], prob_tables: Dict[int, Dict], max_order: int = 3) -> float:\n    total_logprob = 0.0\n    total_tokens = 0\n    for w in corpus:\n        seq = [VOCAB_EXTRA] + list(w) + [VOCAB_EXTRA]\n        for i in range(1, len(seq)):\n            # context is tokens before position i, but we only use up to max_order-1 last tokens\n            left = tuple(seq[max(0, i - (max_order-1)):i])  # last up to max_order-1 tokens\n            tokens_list, probs_arr, used_order = get_distribution_with_backoff(left, prob_tables, max_order)\n            # find index of actual next token\n            next_tok = seq[i]\n            try:\n                idx = tokens_list.index(next_tok)\n            except ValueError:\n                # shouldn't happen because smoothing gave positive prob to all vocab tokens\n                prob = 1e-12\n            else:\n                prob = probs_arr[idx]\n            total_logprob += math.log(prob)\n            total_tokens += 1\n    nll = - total_logprob / total_tokens\n    return nll\n\nnll_value = compute_nll_dataset(words, prob_tables, max_order=MAX_ORDER)\nprint(f\"Training-set NLL (avg negative log prob per token): {nll_value:.4f}\")\nprint(f\"Perplexity (exp(NLL)): {math.exp(nll_value):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:22:19.167891Z","iopub.execute_input":"2025-12-03T16:22:19.168306Z","iopub.status.idle":"2025-12-03T16:22:19.685131Z","shell.execute_reply.started":"2025-12-03T16:22:19.168261Z","shell.execute_reply":"2025-12-03T16:22:19.684129Z"}},"outputs":[{"name":"stdout","text":"Training-set NLL (avg negative log prob per token): 2.2126\nPerplexity (exp(NLL)): 9.1393\n","output_type":"stream"}],"execution_count":10}]}
